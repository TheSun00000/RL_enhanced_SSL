{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as vision_F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck, conv1x1\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Type, List, Optional, Callable\n",
    "\n",
    "from utils.networks import build_resnet18\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10('dataset')\n",
    "\n",
    "class OneImageDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.img = transforms.ToTensor()(train_dataset[0][0])\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self,):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.img\n",
    "\n",
    "def one_image_dataloader(num_steps, batch_size):\n",
    "\n",
    "    return DataLoader(\n",
    "        OneImageDataset(num_steps*batch_size),\n",
    "        batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embed_size, \n",
    "            encoder_dim, \n",
    "            decoder_dim,\n",
    "            num_transforms=4,\n",
    "            num_discrete_magnitude=11,\n",
    "            seq_length=10,\n",
    "            drop_prob=0.3\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        #save the model param\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "\n",
    "        self.num_transforms = num_transforms\n",
    "        self.num_discrete_magnitude = num_discrete_magnitude\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        \n",
    "        self.action_embd = nn.Embedding(3, embed_size)\n",
    "        self.branch_embd = nn.Embedding(2, embed_size)\n",
    "\n",
    "        self.lstm_cell = nn.LSTMCell(embed_size + encoder_dim, decoder_dim, bias=True)        \n",
    "        \n",
    "        self.fcn_transform = nn.Linear(decoder_dim,num_transforms)\n",
    "        self.fcn_magnitude = nn.Linear(decoder_dim,num_discrete_magnitude)\n",
    "\n",
    "        self.drop = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.value_net_1 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.value_net_2 = nn.Linear(256, 1)\n",
    "\n",
    "    \n",
    "\n",
    "    def init_hidden_state(self, batch_size):\n",
    "        h = torch.zeros(batch_size, self.decoder_dim, device=device)\n",
    "        c = torch.zeros(batch_size, self.decoder_dim, device=device)\n",
    "        return h, c\n",
    "    \n",
    "\n",
    "    def forward(self, z1):\n",
    "\n",
    "        #get the seq length to iterate\n",
    "        seq_length = self.seq_length\n",
    "        batch_size = z1.size(0)\n",
    "                \n",
    "        # Initialize LSTM state\n",
    "        h, c = self.init_hidden_state(batch_size)  # (batch_size, decoder_dim)\n",
    "        \n",
    "        preds_transform = torch.zeros(batch_size, 1, seq_length, self.num_transforms).to(device)\n",
    "        preds_magnitude = torch.zeros(batch_size, 1, seq_length, self.num_discrete_magnitude).to(device)\n",
    "\n",
    "        transform_action_id = torch.full((batch_size,), 0, dtype=torch.long, device=device)\n",
    "        magnitude_action_id = torch.full((batch_size,), 1, dtype=torch.long, device=device)\n",
    "\n",
    "        branch_id = torch.full((batch_size,2), 0, dtype=torch.long, device=device)\n",
    "        branch_id[:, 1] = 0\n",
    "\n",
    "        transform_action_embd = self.action_embd(transform_action_id)\n",
    "        magnitude_action_embd = self.action_embd(magnitude_action_id)\n",
    "        \n",
    "        features = [z1]\n",
    "        \n",
    "        for branch in range(1):\n",
    "            for step in range(seq_length):\n",
    "\n",
    "                lstm_input = torch.cat((transform_action_embd, features[branch]), dim=-1)\n",
    "                h, c = self.lstm_cell(lstm_input, (h, c))\n",
    "                output_transform = self.fcn_transform(self.drop(h))\n",
    "\n",
    "                lstm_input = torch.cat((magnitude_action_embd, features[branch]), dim=-1)\n",
    "                h, c = self.lstm_cell(lstm_input, (h, c))\n",
    "                output_magnitude = self.fcn_magnitude(self.drop(h))\n",
    "                \n",
    "                preds_transform[:, branch, step] = output_transform\n",
    "                preds_magnitude[:, branch, step] = output_magnitude\n",
    "        \n",
    "\n",
    "        # print(h.min().item(), h.mean().item(), h.max().item())\n",
    "\n",
    "        value1 = self.value_net_1(h)\n",
    "        # print(value1.min().item(), value1.mean().item(), value1.max().item())\n",
    "        # value = self.value_net_2(self.relu(value1))\n",
    "        # print(value.min().item(), value.mean().item(), value.max().item())\n",
    "        # print('-'*20)\n",
    "\n",
    "\n",
    "        preds_transform = preds_transform.softmax(axis=-1)\n",
    "        preds_magnitude = preds_magnitude.softmax(axis=-1)\n",
    "\n",
    "        return preds_transform, preds_magnitude, value1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMS_DICT = [\n",
    "    ('brightness', vision_F.adjust_brightness, (0.0, 2)),\n",
    "    ('contrast', vision_F.adjust_contrast, (0.1, 1.9)),\n",
    "    ('saturation', vision_F.adjust_saturation, (0.1, 1.9)),\n",
    "    ('hue', vision_F.adjust_hue, (-0.45, 0.45)),\n",
    "]\n",
    "\n",
    "def get_transforms_list(actions_transform, actions_magnitude):\n",
    "\n",
    "    all_transform_lists = []\n",
    "    for i in range(actions_transform.size(0)):\n",
    "        for branch in range(actions_transform.size(1)):\n",
    "            transform_list = []\n",
    "            for s in range(actions_transform.size(2)):\n",
    "                transform_id = actions_transform[i, branch, s].item()\n",
    "                magnitude_id = actions_magnitude[i, branch, s].item()\n",
    "                func_name, func, (lower, upper) = TRANSFORMS_DICT[transform_id]\n",
    "                step = (upper - lower) / 4\n",
    "                magnitude = np.arange(start=lower, stop=upper+step, step=step)[magnitude_id]\n",
    "                transform_list.append((func_name, func, round(magnitude, 5)))\n",
    "            all_transform_lists.append(transform_list)\n",
    "\n",
    "    return all_transform_lists\n",
    "\n",
    "\n",
    "def apply_transformations(x1, transform_list):\n",
    "\n",
    "    num_samples = x1.size(0)\n",
    "    stored_imgs = torch.zeros((num_samples, 3, 32, 32))\n",
    "\n",
    "    for i in range(x1.size(0)):\n",
    "        img = x1[i]\n",
    "        # print('-----')\n",
    "        for transform_name, transform_func, magnitude in transform_list[i]:\n",
    "            # print('before:',img.max())\n",
    "            img = transform_func(img, magnitude)\n",
    "            # print('after:',img.max())\n",
    "        stored_imgs[i] = img\n",
    "\n",
    "    return stored_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_dimensional_multinomial(x):\n",
    "    *leading_axes, last_ax = x.shape\n",
    "    x = x.reshape((-1, last_ax))\n",
    "    actions = torch.multinomial(x, 1)\n",
    "    actions = actions.reshape(leading_axes)\n",
    "    return actions\n",
    "\n",
    "\n",
    "def collect_trajectories(len_trajectory, encoder, decoder, batch_size):\n",
    "\n",
    "    assert len_trajectory % batch_size == 0\n",
    "\n",
    "    data_loader = one_image_dataloader(\n",
    "        num_steps=len_trajectory // batch_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    encoder_dim = 512\n",
    "\n",
    "\n",
    "    stored_z = torch.zeros((len_trajectory, encoder_dim))\n",
    "    stored_value = torch.zeros((len_trajectory,))\n",
    "    stored_preds_transform = torch.zeros((len_trajectory, 1, decoder.seq_length, decoder.num_transforms))\n",
    "    stored_preds_magnitude = torch.zeros((len_trajectory, 1, decoder.seq_length, decoder.num_discrete_magnitude))\n",
    "    stored_actions_transform = torch.zeros((len_trajectory, 1, decoder.seq_length, 1), dtype=torch.long)\n",
    "    stored_actions_magnitude = torch.zeros((len_trajectory, 1, decoder.seq_length, 1), dtype=torch.long)\n",
    "    stored_rewards = torch.zeros((len_trajectory,))\n",
    "\n",
    "    data_loader_iterator = iter(data_loader)\n",
    "    for i in range(len_trajectory // batch_size):\n",
    "    # for i in tqdm(range(len_trajectory // batch_size)):\n",
    "\n",
    "        begin, end = i*batch_size, (i+1)*batch_size\n",
    "\n",
    "        img = next(data_loader_iterator)\n",
    "\n",
    "        img = img.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, z = encoder(img)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds_transform, preds_magnitude, value = decoder(z)\n",
    "\n",
    "        actions_transform = preds_transform.argmax(dim=-1).unsqueeze(-1)\n",
    "        # actions_magnitude = preds_magnitude.argmax(dim=-1).unsqueeze(-1)\n",
    "        actions_magnitude = multi_dimensional_multinomial(preds_magnitude).unsqueeze(-1)\n",
    "        transforms_list = get_transforms_list(actions_transform, actions_magnitude)\n",
    "        # print(transforms_list[0])      \n",
    "        new_img = apply_transformations(img, transforms_list)\n",
    "\n",
    "        # print(img[:, 0, 0, 0], new_img[:, 0, 0, 0])\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     new_logits, new_z = encoder(new_img)\n",
    "\n",
    "\n",
    "        stored_z[begin:end] = z.detach().cpu()\n",
    "        stored_value[begin:end] = value.reshape(-1).detach().cpu()\n",
    "        stored_preds_transform[begin:end] = preds_transform.detach().cpu()\n",
    "        stored_preds_magnitude[begin:end] = preds_magnitude.detach().cpu()\n",
    "        stored_actions_transform[begin:end] = actions_transform.detach().cpu()\n",
    "        stored_actions_magnitude[begin:end] = actions_magnitude.detach().cpu()\n",
    "        stored_rewards[begin:end] = 1 - new_img.reshape(batch_size, -1).mean(axis=1)\n",
    "\n",
    "    return (\n",
    "            stored_z, stored_value, \n",
    "            (stored_preds_transform, stored_preds_magnitude),\n",
    "            (stored_actions_transform, stored_actions_magnitude),\n",
    "            stored_rewards\n",
    "        ), (img, new_img)\n",
    "\n",
    "# trajectory = collect_trajectories(1024, encoder, decoder, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_trajectory(trajectory):\n",
    "\n",
    "    (\n",
    "        stored_z, stored_value, \n",
    "        (stored_preds_transform, stored_preds_magnitude),\n",
    "        (stored_actions_transform, stored_actions_magnitude),\n",
    "        stored_rewards\n",
    "    ) = trajectory\n",
    "\n",
    "    permutation = torch.randperm(stored_z.size()[0])\n",
    "\n",
    "    random_stored_z = stored_z[permutation]\n",
    "    random_stored_value = stored_value[permutation]\n",
    "    random_stored_preds_transform = stored_preds_transform[permutation]\n",
    "    random_stored_preds_magnitude = stored_preds_magnitude[permutation]\n",
    "    random_stored_actions_transform = stored_actions_transform[permutation]\n",
    "    random_stored_actions_magnitude = stored_actions_magnitude[permutation]\n",
    "    random_stored_rewards = stored_rewards[permutation]\n",
    "\n",
    "    random_trajectory = (\n",
    "        random_stored_z, random_stored_value,\n",
    "        (random_stored_preds_transform, random_stored_preds_magnitude),\n",
    "        (random_stored_actions_transform, random_stored_actions_magnitude),\n",
    "        random_stored_rewards\n",
    "    )\n",
    "\n",
    "    return random_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-12\n",
    "    log_probabilities = torch.log(probabilities + epsilon)\n",
    "    entropy = -torch.sum(probabilities * log_probabilities, dim=-1)\n",
    "    return entropy\n",
    "\n",
    "def ppo_update(trajectory, decoder, optimizer, value_criterion, ppo_batch_size=256):\n",
    "\n",
    "    shuffled_trajectory = shuffle_trajectory(trajectory)\n",
    "\n",
    "    (\n",
    "        stored_z, stored_value,\n",
    "        (stored_preds_transform, stored_preds_magnitude),\n",
    "        (stored_actions_transform, stored_actions_magnitude),\n",
    "        stored_rewards\n",
    "    ) = shuffled_trajectory\n",
    "\n",
    "    len_trajectory = stored_z.shape[0]\n",
    "\n",
    "\n",
    "    assert len_trajectory % ppo_batch_size == 0\n",
    "\n",
    "    acc_loss = 0\n",
    "    for i in range(len_trajectory // ppo_batch_size):\n",
    "\n",
    "        begin, end = i*ppo_batch_size, (i+1)*ppo_batch_size\n",
    "\n",
    "        z = stored_z[begin:end].to(device)\n",
    "        old_preds_transform = stored_preds_transform[begin:end].to(device)\n",
    "        old_preds_magnitude = stored_preds_magnitude[begin:end].to(device)\n",
    "        old_actions_transform = stored_actions_transform[begin:end].to(device)\n",
    "        old_actions_magnitude = stored_actions_magnitude[begin:end].to(device)\n",
    "        reward = stored_rewards[begin:end].to(device)\n",
    "\n",
    "        new_preds_transform, new_preds_magnitude, new_value = decoder(z)\n",
    "        new_value = new_value.reshape(-1)\n",
    "        \n",
    "        entropy_loss = calculate_entropy(new_preds_transform).mean() + calculate_entropy(new_preds_magnitude).mean()\n",
    "        entropy_loss = -1. *  entropy_loss\n",
    "\n",
    "        # print('entropy:', entropy.item())\n",
    "\n",
    "        \n",
    "\n",
    "        # print(old_preds_transform.sum(axis=-1).mean())\n",
    "        # print(old_preds_magnitude.sum(axis=-1).mean())\n",
    "        # print(new_preds_transform.sum(axis=-1).mean())\n",
    "        # print(new_preds_magnitude.sum(axis=-1).mean())\n",
    "\n",
    "\n",
    "        old_pi = torch.concatenate((\n",
    "            old_preds_transform.gather(-1, old_actions_transform),\n",
    "            old_preds_magnitude.gather(-1, old_actions_magnitude)\n",
    "        ), dim=-1)\n",
    "\n",
    "        new_pi = torch.concatenate((\n",
    "            new_preds_transform.gather(-1, old_actions_transform),\n",
    "            new_preds_magnitude.gather(-1, old_actions_magnitude)\n",
    "        ), dim=-1)\n",
    "\n",
    "\n",
    "        old_pi = old_pi.reshape(ppo_batch_size, -1)\n",
    "        new_pi = new_pi.reshape(ppo_batch_size, -1)\n",
    "\n",
    "        # print(new_pi.shape, old_pi.shape)\n",
    "\n",
    "        advantage = reward\n",
    "        advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)\n",
    "        # print(reward)\n",
    "        advantage = advantage.unsqueeze(-1)\n",
    "        ratio = torch.exp(torch.log(new_pi) - torch.log(old_pi).detach())\n",
    "\n",
    "        # print(advantage.min(), advantage.max())\n",
    "\n",
    "        # print('ratio:', ratio.shape)\n",
    "        # print('advantage:', advantage.shape)\n",
    "\n",
    "        # print(ratio)\n",
    "\n",
    "        surr1 = ratio * advantage\n",
    "        surr2 = torch.clamp(ratio, 1-0.2, 1+0.2) * advantage\n",
    "\n",
    "        actor_loss = - torch.min(surr1, surr2).mean()\n",
    "        # value_loss = value_criterion(new_value, reward)\n",
    "\n",
    "        \n",
    "        # print('actor_loss:', actor_loss.item())\n",
    "        # print('value_loss:', value_loss.item())\n",
    "        # print('new_value:', new_value.mean())\n",
    "        # print('reward:', reward.mean())\n",
    "\n",
    "\n",
    "        loss = actor_loss + 0.05*entropy_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_loss += loss.item()\n",
    "\n",
    "    return acc_loss / (i+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "\n",
    "    encoder = build_resnet18()\n",
    "    encoder.load_state_dict(torch.load('resnet18-f37072fd.pth'))\n",
    "    encoder = encoder.to(device)\n",
    "\n",
    "    decoder = DecoderRNN(\n",
    "        embed_size=1024,\n",
    "        encoder_dim=512,\n",
    "        decoder_dim=512,\n",
    "        num_transforms=4,\n",
    "        num_discrete_magnitude=5,\n",
    "        seq_length=4\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        decoder.parameters(),\n",
    "        lr=0.0005\n",
    "    )\n",
    "\n",
    "    value_criterion = nn.MSELoss()\n",
    "    list(decoder.parameters())[-1]\n",
    "\n",
    "    return encoder, decoder, optimizer, value_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step: 6      Reward: 1.000000        Loss: -0.094071:  12%|█▏        | 6/50 [00:02<00:15,  2.85it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.080622:   8%|▊         | 4/50 [00:01<00:21,  2.17it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.082588:   6%|▌         | 3/50 [00:01<00:20,  2.32it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.094084:   8%|▊         | 4/50 [00:02<00:24,  1.89it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.073565:   8%|▊         | 4/50 [00:02<00:30,  1.49it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.084688:   8%|▊         | 4/50 [00:01<00:22,  2.02it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.096706:   4%|▍         | 2/50 [00:01<00:24,  1.92it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.096505:   4%|▍         | 2/50 [00:00<00:22,  2.17it/s]\n",
      "Step: 6      Reward: 1.000000        Loss: -0.099143:  12%|█▏        | 6/50 [00:03<00:28,  1.57it/s]\n",
      "Step: 5      Reward: 1.000000        Loss: -0.082095:  10%|█         | 5/50 [00:03<00:27,  1.66it/s]\n",
      "Step: 49      Reward: 0.995037        Loss: -0.114509: 100%|██████████| 50/50 [00:15<00:00,  3.27it/s]\n",
      "Step: 5      Reward: 1.000000        Loss: -0.097266:  10%|█         | 5/50 [00:04<00:39,  1.15it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.078216:   8%|▊         | 4/50 [00:01<00:15,  2.94it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.090460:   8%|▊         | 4/50 [00:01<00:19,  2.39it/s]\n",
      "Step: 5      Reward: 1.000000        Loss: -0.087535:  10%|█         | 5/50 [00:01<00:16,  2.71it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.085104:   8%|▊         | 4/50 [00:01<00:17,  2.61it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.083778:   8%|▊         | 4/50 [00:02<00:24,  1.85it/s]\n",
      "Step: 12      Reward: 1.000000        Loss: -0.076791:  24%|██▍       | 12/50 [00:04<00:13,  2.87it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.092638:   8%|▊         | 4/50 [00:01<00:21,  2.13it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.088589:   6%|▌         | 3/50 [00:01<00:20,  2.29it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.092598:   4%|▍         | 2/50 [00:00<00:20,  2.32it/s]\n",
      "Step: 13      Reward: 1.000000        Loss: -0.086045:  26%|██▌       | 13/50 [00:04<00:11,  3.12it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.095302:   4%|▍         | 2/50 [00:01<00:29,  1.62it/s]\n",
      "Step: 10      Reward: 1.000000        Loss: -0.095098:  20%|██        | 10/50 [00:06<00:25,  1.56it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.084429:   8%|▊         | 4/50 [00:02<00:32,  1.40it/s]\n",
      "Step: 12      Reward: 1.000000        Loss: -0.085329:  24%|██▍       | 12/50 [00:03<00:12,  3.11it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.086317:   6%|▌         | 3/50 [00:01<00:21,  2.23it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.087136:   8%|▊         | 4/50 [00:01<00:20,  2.20it/s]\n",
      "Step: 8      Reward: 1.000000        Loss: -0.086095:  16%|█▌        | 8/50 [00:02<00:15,  2.71it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.091840:   6%|▌         | 3/50 [00:01<00:20,  2.27it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.083355:   8%|▊         | 4/50 [00:01<00:19,  2.33it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.090132:   6%|▌         | 3/50 [00:01<00:21,  2.19it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.093614:   4%|▍         | 2/50 [00:01<00:38,  1.23it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.095873:   4%|▍         | 2/50 [00:01<00:32,  1.47it/s]\n",
      "Step: 38      Reward: 1.000000        Loss: -0.089177:  76%|███████▌  | 38/50 [00:12<00:03,  3.05it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.092609:   8%|▊         | 4/50 [00:01<00:19,  2.32it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.090183:   8%|▊         | 4/50 [00:02<00:27,  1.70it/s]\n",
      "Step: 6      Reward: 1.000000        Loss: -0.091436:  12%|█▏        | 6/50 [00:03<00:23,  1.91it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.081542:   8%|▊         | 4/50 [00:01<00:22,  2.01it/s]\n",
      "Step: 15      Reward: 1.000000        Loss: -0.093219:  30%|███       | 15/50 [00:07<00:17,  2.00it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.088632:   8%|▊         | 4/50 [00:02<00:27,  1.68it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.083940:   6%|▌         | 3/50 [00:01<00:27,  1.71it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.080008:   6%|▌         | 3/50 [00:01<00:28,  1.67it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.094839:   6%|▌         | 3/50 [00:01<00:25,  1.87it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.090860:   8%|▊         | 4/50 [00:02<00:26,  1.71it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.086572:   6%|▌         | 3/50 [00:01<00:28,  1.63it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.092441:   4%|▍         | 2/50 [00:00<00:20,  2.36it/s]\n",
      "Step: 5      Reward: 1.000000        Loss: -0.083706:  10%|█         | 5/50 [00:01<00:15,  2.86it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.082358:   8%|▊         | 4/50 [00:01<00:17,  2.59it/s]\n",
      "Step: 49      Reward: 0.998545        Loss: -0.111616: 100%|██████████| 50/50 [00:13<00:00,  3.73it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.089486:   8%|▊         | 4/50 [00:01<00:20,  2.25it/s]\n",
      "Step: 8      Reward: 1.000000        Loss: -0.082662:  16%|█▌        | 8/50 [00:03<00:17,  2.35it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.083457:   8%|▊         | 4/50 [00:01<00:18,  2.42it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.082979:   8%|▊         | 4/50 [00:01<00:22,  2.03it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.088547:   8%|▊         | 4/50 [00:02<00:27,  1.66it/s]\n",
      "Step: 49      Reward: 0.625210        Loss: -0.099543: 100%|██████████| 50/50 [00:29<00:00,  1.71it/s]\n",
      "Step: 49      Reward: 0.706757        Loss: -0.069382: 100%|██████████| 50/50 [00:29<00:00,  1.71it/s]\n",
      "Step: 11      Reward: 1.000000        Loss: -0.092333:  22%|██▏       | 11/50 [00:06<00:21,  1.81it/s]\n",
      "Step: 49      Reward: 0.707297        Loss: -0.069126: 100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n",
      "Step: 11      Reward: 1.000000        Loss: -0.104859:  22%|██▏       | 11/50 [00:04<00:15,  2.49it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.085512:   8%|▊         | 4/50 [00:02<00:24,  1.84it/s]\n",
      "Step: 9      Reward: 1.000000        Loss: -0.089096:  18%|█▊        | 9/50 [00:04<00:20,  1.95it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.087629:   8%|▊         | 4/50 [00:01<00:22,  2.06it/s]\n",
      "Step: 5      Reward: 1.000000        Loss: -0.092986:  10%|█         | 5/50 [00:02<00:18,  2.40it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.094704:   4%|▍         | 2/50 [00:01<00:28,  1.66it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.078223:   6%|▌         | 3/50 [00:01<00:25,  1.86it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.088904:   6%|▌         | 3/50 [00:01<00:24,  1.92it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.094406:   4%|▍         | 2/50 [00:00<00:21,  2.25it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.094091:   4%|▍         | 2/50 [00:01<00:28,  1.71it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.094014:   8%|▊         | 4/50 [00:01<00:17,  2.62it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.086279:   8%|▊         | 4/50 [00:01<00:20,  2.26it/s]\n",
      "Step: 49      Reward: 0.707517        Loss: -0.070342: 100%|██████████| 50/50 [00:31<00:00,  1.59it/s]\n",
      "Step: 5      Reward: 1.000000        Loss: -0.089692:  10%|█         | 5/50 [00:02<00:18,  2.47it/s]\n",
      "Step: 49      Reward: 0.633906        Loss: -0.069033: 100%|██████████| 50/50 [01:00<00:00,  1.21s/it]\n",
      "Step: 5      Reward: 1.000000        Loss: -0.079471:  10%|█         | 5/50 [00:02<00:24,  1.87it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.086922:   6%|▌         | 3/50 [00:01<00:24,  1.95it/s]\n",
      "Step: 17      Reward: 1.000000        Loss: -0.084739:  34%|███▍      | 17/50 [00:05<00:11,  2.90it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.090482:   8%|▊         | 4/50 [00:01<00:19,  2.39it/s]\n",
      "Step: 11      Reward: 1.000000        Loss: -0.087231:  22%|██▏       | 11/50 [00:03<00:12,  3.03it/s]\n",
      "Step: 9      Reward: 1.000000        Loss: -0.088897:  18%|█▊        | 9/50 [00:04<00:21,  1.93it/s]\n",
      "Step: 11      Reward: 1.000000        Loss: -0.101854:  22%|██▏       | 11/50 [00:08<00:29,  1.33it/s]\n",
      "Step: 7      Reward: 1.000000        Loss: -0.091814:  14%|█▍        | 7/50 [00:03<00:21,  2.01it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.092963:   4%|▍         | 2/50 [00:00<00:17,  2.68it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.094213:   4%|▍         | 2/50 [00:00<00:17,  2.68it/s]\n",
      "Step: 4      Reward: 1.000000        Loss: -0.091820:   8%|▊         | 4/50 [00:01<00:17,  2.66it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.083551:   6%|▌         | 3/50 [00:01<00:20,  2.26it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.096629:   4%|▍         | 2/50 [00:01<00:30,  1.59it/s]\n",
      "Step: 49      Reward: 0.997438        Loss: -0.114855: 100%|██████████| 50/50 [00:13<00:00,  3.62it/s]\n",
      "Step: 3      Reward: 1.000000        Loss: -0.087487:   6%|▌         | 3/50 [00:01<00:19,  2.44it/s]\n",
      "Step: 9      Reward: 1.000000        Loss: -0.093301:  18%|█▊        | 9/50 [00:04<00:19,  2.13it/s]\n",
      "Step: 2      Reward: 1.000000        Loss: -0.098989:   4%|▍         | 2/50 [00:00<00:22,  2.14it/s]\n",
      "Step: 13      Reward: 1.000000        Loss: -0.096613:  26%|██▌       | 13/50 [00:05<00:15,  2.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[258], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     encoder, decoder, optimizer, value_criterion \u001b[38;5;241m=\u001b[39m \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m     tqdm_range \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m))\n",
      "Cell \u001b[0;32mIn[252], line 3\u001b[0m, in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_resnet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     encoder\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet18-f37072fd.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Script/RL_contrastive/utils/networks.py:134\u001b[0m, in \u001b[0;36mbuild_resnet18\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_resnet18\u001b[39m():\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBasicBlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Script/RL_contrastive/utils/networks.py:56\u001b[0m, in \u001b[0;36mResNet.__init__\u001b[0;34m(self, block, layers, num_classes, zero_init_residual, groups, width_per_group, replace_stride_with_dilation, norm_layer)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules():\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, nn\u001b[38;5;241m.\u001b[39mConv2d):\n\u001b[0;32m---> 56\u001b[0m         \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_normal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfan_out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonlinearity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, (nn\u001b[38;5;241m.\u001b[39mBatchNorm2d, nn\u001b[38;5;241m.\u001b[39mGroupNorm)):\n\u001b[1;32m     58\u001b[0m         nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mconstant_(m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/init.py:458\u001b[0m, in \u001b[0;36mkaiming_normal_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    456\u001b[0m std \u001b[38;5;241m=\u001b[39m gain \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(fan)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "\n",
    "    encoder, decoder, optimizer, value_criterion = init()\n",
    "\n",
    "    rewards = []\n",
    "\n",
    "\n",
    "    tqdm_range = tqdm(range(50))\n",
    "    for step in tqdm_range:\n",
    "\n",
    "        trajectory, (img, new_img) = collect_trajectories(\n",
    "            len_trajectory=1024,\n",
    "            encoder=encoder,\n",
    "            decoder=decoder,\n",
    "            batch_size=1024\n",
    "        )\n",
    "\n",
    "        loss = ppo_update(\n",
    "            trajectory,\n",
    "            decoder,\n",
    "            optimizer,\n",
    "            ppo_batch_size=1024,\n",
    "            value_criterion=value_criterion\n",
    "        )\n",
    "\n",
    "        reward = float(trajectory[-1].mean())\n",
    "\n",
    "        # print(f'Step: {step}      Reward: {reward:.6f}        Loss: {loss:.6f}')\n",
    "        # print(trajectory[2][1][0])s\n",
    "\n",
    "        tqdm_range.set_description(f'Step: {step}      Reward: {reward:.6f}        Loss: {loss:.6f}')\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "        if reward == 1:\n",
    "            break\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6317fbb550>]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand([1024, 1, 1, 4]).softmax(-1)\n",
    "a[..., 1] = 100.\n",
    "a[1, 0, 0, 0] = 20000.\n",
    "multi_dimensional_multinomial(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
