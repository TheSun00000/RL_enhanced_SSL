{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import  DataLoader\n",
    "from tqdm import tqdm\n",
    "from itertools import permutations\n",
    "\n",
    "\n",
    "from math import factorial\n",
    "\n",
    "from utils.networks import DecoderRNN, build_resnet18\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderNoInput(nn.Module):\n",
    "    def __init__(self,\n",
    "            num_transforms,\n",
    "            num_discrete_magnitude,\n",
    "            device\n",
    "            ):\n",
    "        super().__init__()\n",
    "    \n",
    "    #save the model param\n",
    "\n",
    "        self.num_transforms = num_transforms\n",
    "        self.num_discrete_magnitude = num_discrete_magnitude\n",
    "        self.seq_length = num_transforms\n",
    "        self.device = device\n",
    "        \n",
    "        self.permutations = torch.tensor(\n",
    "            list(permutations(range(4)))\n",
    "            ).to(device)\n",
    "        \n",
    "        self.num_transforms_permutations = len(self.permutations)\n",
    "        self.num_actions = num_transforms * num_discrete_magnitude\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2 * self.num_actions + 2 * self.num_transforms_permutations),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, batch_size, old_action_index=None):\n",
    "        \n",
    "        x = torch.zeros((batch_size,1), dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        output = self.model(x)\n",
    "        \n",
    "        magnitude_logits = output[:, :2 * self.num_actions]\n",
    "        permutations_logits = output[:, 2 * self.num_actions:]\n",
    "        \n",
    "        magnitude_logits = magnitude_logits.reshape(batch_size, 2, self.num_transforms, self.num_discrete_magnitude)\n",
    "        permutations_logits = permutations_logits.reshape(batch_size, 2, self.num_transforms_permutations)\n",
    "        \n",
    "        magnitude_dist = torch.distributions.Categorical(logits=magnitude_logits)\n",
    "        permutations_dist = torch.distributions.Categorical(logits=permutations_logits)\n",
    "        \n",
    "        if old_action_index is None:\n",
    "            magnitude_actions_index = magnitude_dist.sample()\n",
    "            permutations_index = permutations_dist.sample()\n",
    "        else:\n",
    "            transform_actions_index, magnitude_actions_index = old_action_index\n",
    "            matches = torch.all(transform_actions_index.unsqueeze(0) == self.permutations.unsqueeze(1).unsqueeze(1), dim=-1) * 1\n",
    "            permutations_index = torch.argmax(matches, dim=0)\n",
    "            magnitude_actions_index = magnitude_actions_index\n",
    "                \n",
    "        magnitude_log_p = F.log_softmax(magnitude_logits, dim=-1).gather(-1, magnitude_actions_index.unsqueeze(-1)).reshape(batch_size, -1).sum(-1, keepdim=True)\n",
    "        permutation_log_p = F.log_softmax(permutations_logits, dim=-1).gather(-1, permutations_index.unsqueeze(-1)).reshape(batch_size, -1).sum(-1, keepdim=True)\n",
    "        \n",
    "        log_p = magnitude_log_p + permutation_log_p\n",
    "        transform_actions_index = self.permutations[permutations_index]\n",
    "        magnitude_actions_index = magnitude_actions_index\n",
    "        transform_entropy = permutations_dist.entropy().mean()\n",
    "        magnitude_entropy = magnitude_dist.entropy().mean()\n",
    "        \n",
    "        # print(log_p.shape)\n",
    "        # print(transform_actions_index.shape)\n",
    "        # print(magnitude_actions_index.shape)\n",
    "        # print(transform_entropy.shape)\n",
    "        # print(magnitude_entropy.shape)\n",
    "        \n",
    "        return (\n",
    "                log_p,\n",
    "                (transform_actions_index, magnitude_actions_index),\n",
    "                (transform_entropy, magnitude_entropy)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecoderNoInput(4, 11, device).to(device)\n",
    "batch_size = 1024\n",
    "log_p, (transform_actions_index, magnitude_actions_index), (transform_entropy, magnitude_entropy) = model(batch_size)\n",
    "new_log_p, (new_transform_actions_index, new_magnitude_actions_index), (transform_entropy, magnitude_entropy) = model(\n",
    "    batch_size, \n",
    "    old_action_index=(transform_actions_index, magnitude_actions_index)\n",
    ")\n",
    "\n",
    "assert torch.isclose(log_p, new_log_p).all()\n",
    "assert torch.isclose(transform_actions_index, new_transform_actions_index).all()\n",
    "assert torch.isclose(magnitude_actions_index, new_magnitude_actions_index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.tensor(list(permutations(range(4)))).to(device)\n",
    "x = transform_actions_index.reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 11, 11,  ..., 23,  4, 15], device='cuda:0')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = torch.all(p.unsqueeze(1) == x.unsqueeze(0), dim=-1) * 1\n",
    "indices = torch.argmax(matches, dim=0)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2048, 4]), torch.Size([24, 1, 4]))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(0).shape, p.unsqueeze(1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
